new_data <- original_data
new_data$Pf <- simulated_response[,1]
out[i] <- estimator(new_data)
}
return(out)
}
# Run bootstrapping
set.seed(123)
peak_temps <- parametric_bootstrap(fit_bin, estimator = peak_temp, nsim = 1000)
# Calculate peak temperature and CI
peak_temp_estimate <- peak_temp(tz_malaria)
ci_lower <- quantile(peak_temps, 0.025)
ci_upper <- quantile(peak_temps, 0.975)
cat("Temperature at which prevalence is highest:", peak_temp_estimate, "\n")
cat("95% Confidence Interval: [", ci_lower, ",", ci_upper, "]\n")
# Estimate change point
estimate_change_point <- function(data, change_points = seq(25, 35, by = 0.1)) {
log_likelihoods <- numeric(length(change_points))
for (i in seq_along(change_points)) {
change_point <- change_points[i]
fit <- glm(cbind(Pf, Ex - Pf) ~ Temperature + pmax(Temperature - change_point, 0),
data = data,
family = binomial)
log_likelihoods[i] <- logLik(fit)
}
optimal_change_point <- change_points[which.max(log_likelihoods)]
return(optimal_change_point)
}
# Estimate change point
estimate_change_point <- function(data, change_points = seq(25, 35, by = 0.1)) {
log_likelihoods <- numeric(length(change_points))
for (i in seq_along(change_points)) {
change_point <- change_points[i]
fit <- glm(cbind(Pf, Ex - Pf) ~ Temperature + pmax(Temperature - change_point, 0),
data = data,
family = binomial)
log_likelihoods[i] <- logLik(fit)
}
optimal_change_point <- change_points[which.max(log_likelihoods)]
return(optimal_change_point)
}
opt_cp <- estimate_change_point(tz_malaria)
# Fit linear spline model
fit_bin_sp <- glm(cbind(Pf, Ex - Pf) ~ Temperature + pmax(Temperature - opt_cp, 0),
data = tz_malaria,
family = binomial)
# Bootstrapping for change point
cp_boot <- parametric_bootstrap(fit = fit_bin_sp,
estimator = estimate_change_point,
nsim = 100)
ci_lower_cp <- quantile(cp_boot, 0.025)
ci_upper_cp <- quantile(cp_boot, 0.975)
cat("Estimate of the change point in temperature:", opt_cp, "\n")
cat("95% Confidence Interval: [", ci_lower_cp, ",", ci_upper_cp, "]\n")
# Plot empirical logit with GAM and linear spline
tz_malaria$predicted_sp <- predict(fit_bin_sp)
p_spl <- ggplot(tz_malaria, aes(x = Temperature, y = elogit)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "gam", formula = y ~ s(x, bs = "cs"), color = "blue") +
geom_line(aes(y = predicted_sp), color = "red") +
labs(title = "Empirical logit vs Temperature",
x = "Temperature (°C)",
y = "Empirical logit") +
theme_minimal()
ggplot(tz_malaria, aes(x = Temperature, y = elogit)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "gam", formula = y ~ s(x, bs = "cs"), color = "blue") +
geom_line(aes(y = predicted_sp), color = "red") +
labs(title = "Empirical logit vs Temperature",
x = "Temperature (°C)",
y = "Empirical logit") +
theme_minimal()
library(lme4)
# Fit GLMM
fit2_glmer <- glmer(cbind(Pf, Ex - Pf) ~ Temperature + pmax(Temperature - opt_cp, 0) +
EVI + (1 | cluster.number),
data = tz_malaria, nAGQ = 100,
family = binomial)
# Fit GLMM
fit2_glmer <- glmer(cbind(Pf, Ex - Pf) ~ Temperature + pmax(Temperature - opt_cp, 0) +
EVI + (1 | cluster.number),
data = tz_malaria, nAGQ = 100,
family = binomial)
summary(fit2_glmer)
library(sf)
library(rgeoboundaries)
library(terra)
# Convert to sf object
tz_sf <- st_as_sf(tz_malaria, coords = c("utm_x", "utm_y"), crs = 32736)
# Download Tanzania boundary
shp_tz <- geoboundaries(country = "tanzania", adm_lvl = "adm0")
shp_tz <- st_transform(shp_tz, crs = 32736)
# Create a 5 km grid
grid_utm <- create_grid(shp_tz, spat_res = 5)
# Read and project raster files
r_temp <- rast("../Data/Tanzania_Annual_LST_2015.tif")
r_temp <- terra::project(r_temp, "EPSG:32736")
r_evi <- rast("../Data//Tanzania_Annual_EVI_2015.tif")
r_evi <- terra::project(r_evi, "EPSG:32736")
# Extract values and predict prevalence
pred_data_frame <- data.frame(
Temperature = extract(r_temp, st_coordinates(grid_utm))[,1],
EVI = extract(r_evi, st_coordinates(grid_utm))[,1]
)
pred_glmer <- predict(fit2_glmer, newdata = pred_data_frame, type = "response", re.form = NA)
# Create raster plot
raster_pred <- data.frame(
x = st_coordinates(grid_utm)[, 1],
y = st_coordinates(grid_utm)[, 2],
prev = pred_glmer
)
ggplot(data = raster_pred) +
geom_raster(aes(x = x, y = y, fill = prev)) +
scale_fill_viridis_c() +
coord_cartesian() +
theme_minimal() +
labs(title = "Predictions", fill = "Prevalence")
rm(list = ls())
library(RiskMap)
library(lme4)
data("tz_malaria")
tz_malaria <- st_as_sf(tz_malaria, coords = c("utm_x", "utm_y"), crs = 32736)
# Point 1
glmer_fit_null <- glmer(cbind(Pf, Ex - Pf) ~ (1 | cluster.number),
data = tz_malaria, nAGQ = 100,
family = binomial)
tz_malaria$Z_hat_null <- ranef(glmer_fit_null)$cluster.number[,1]
tz_vari_null <-
s_variogram(data = tz_malaria, variable = "Z_hat_null",
bins = seq(1,500, length = 15),
scale_to_km = TRUE,
n_permutation = 1000)
plot_s_variogram(tz_vari_null, plot_envelope = TRUE)
seq(1,500, length = 15)
glmer_fit <- glmer(cbind(Pf, Ex - Pf) ~ Temperature + pmax(Temperature - 33, 0) +
EVI + (1 | cluster.number),
data = tz_malaria, nAGQ = 100,
family = binomial)
tz_malaria$Z_hat <- ranef(glmer_fit)$cluster.number[,1]
tz_vari <-
s_variogram(data = tz_malaria, variable = "Z_hat",
bins = seq(1,500, length = 15),
scale_to_km = TRUE,
n_permutation = 1000)
plot_s_variogram(tz_vari, plot_envelope = TRUE)
# Fitting an intercept only model
glgm_fit_null <- glgpm(Pf ~ gp(nugget = NULL),
den = Ex,
data = tz_malaria,
family = "binomial")
summary(glgm_fit_null)
# Fitting a model with covariates
glgm_fit <- glgpm(Pf ~ Temperature + pmax(Temperature - 33, 0) +
EVI + gp(nugget = NULL),
den = Ex,
data = tz_malaria,
family = "binomial")
summary(glgm_fit)
library(ggplot2)
library(dplyr)
# Extract parameters
theta_hat_null <- coef(glgm_fit_null)
theta_hat <- coef(glgm_fit)
# Define a sequence of distances
distances <- seq(0, 1000, length.out = 200)
# Compute variogram values for both models
variogram_df <- data.frame(
Distance = rep(distances, 2),
Variogram = c(
theta_hat_null$tau2 + theta_hat_null$sigma2 * (1 - exp(-distances / theta_hat_null$phi)),
theta_hat$tau2 + theta_hat$sigma2 * (1 - exp(-distances / theta_hat$phi))
),
Model = factor(rep(c("No covariates", "With covariates"), each = length(distances)))
)
# Plot using ggplot2
ggplot(variogram_df, aes(x = Distance, y = Variogram, color = Model)) +
geom_line(size = 1.2) +
labs(
title = "Theoretical Variogram Comparison",
x = "Distance",
y = "Variogram"
) +
theme_minimal() +
scale_color_manual(values = c("blue", "red")) +
theme(
legend.title = element_blank(), # Removes legend title
legend.position = "bottom" # Places legend at the bottom for clarity
)
rm(list = ls())
library(RiskMap)
library(sf)
library(ggplot2)
data("liberia")
# Convert to an sf object
liberia_sf <- st_as_sf(liberia, coords = c("long", "lat"), crs = 4326)
crs_lb <- propose_utm(liberia_sf)
liberia_sf <- st_transform(liberia_sf, crs = crs_lb)
lb_fit <- glgpm(npos ~ log(elevation) + gp(),
den = ntest,
family = "binomial",
data = liberia_sf)
library(rgeoboundaries)
shp_lb <- geoboundaries(country = "liberia", adm_lvl = "adm0")
shp_lb <- st_transform(shp_lb, crs=crs_lb)
grid_lb <- create_grid(shp_lb, spat_res = 5)
library(elevatr)
elevation <- get_elev_point(st_as_sf(grid_lb), prj = crs_lb, src = "aws")$elevation
pred_lb <- data.frame(elvation=elevation)
pred_lb <- data.frame(elevation=elevation)
pred_S_lb <-
pred_over_grid(lb_fit, grid_pred = grid_lb,
predictors = pred_lb)
pred_T_lb <-
pred_target_grid(pred_S_lb,
f_target = list(prev = function(x) exp(x)/(1+exp(x))),
pd_summary = list(mean = mean,
lower_lim = function(x) quantile(x, 0.025),
upper_lim = function(x) quantile(x, 0.975),
exceed20 = function(x) mean(x > 0.2),
exceed30 = function(x) mean(x > 0.3)))
pred_T_lb <-
pred_target_grid(pred_S_lb,
f_target = list(prev = function(x) exp(x)/(1+exp(x))),
pd_summary = list(mean = mean,
lower_lim = function(x) quantile(x, 0.025),
upper_lim = function(x) quantile(x, 0.975),
exceed20 = function(x) mean(x > 0.2),
exceed30 = function(x) mean(x > 0.3)))
pred_lb
pred_lb <- data.frame(elvation=elevation)
pred_S_lb <-
pred_over_grid(lb_fit, grid_pred = grid_lb,
predictors = pred_lb)
pred_T_lb <-
pred_target_grid(pred_S_lb,
f_target = list(prev = function(x) exp(x)/(1+exp(x))),
pd_summary = list(mean = mean,
lower_lim = function(x) quantile(x, 0.025),
upper_lim = function(x) quantile(x, 0.975),
exceed20 = function(x) mean(x > 0.2),
exceed30 = function(x) mean(x > 0.3)))
pred_lb <- data.frame(elevation=elevation)
pred_S_lb <-
pred_over_grid(lb_fit, grid_pred = grid_lb,
predictors = pred_lb)
library(devtools)
load("../RiskMap")
load("../../../../RiskMap/")
load("../../../../RiskMap")
pred_T_lb <-
pred_target_grid(pred_S_lb,
f_target = list(prev = function(x) exp(x)/(1+exp(x))),
pd_summary = list(mean = mean,
lower_lim = function(x) quantile(x, 0.025),
upper_lim = function(x) quantile(x, 0.975),
exceed20 = function(x) mean(x > 0.2),
exceed30 = function(x) mean(x > 0.3)))
pred_target_grid <- function(object,
include_covariates = TRUE,
include_nugget = FALSE,
include_cov_offset = FALSE,
include_mda_effect = TRUE,
mda_grid = NULL,
time_pred = NULL,
include_re = FALSE,
f_target = NULL,
pd_summary = NULL) {
if(!inherits(object,
what = "RiskMap.pred.re", which = FALSE)) {
stop("The object passed to 'object' must be an output of
the function 'pred_over_grid'")
}
dast_model <- !is.null(object$par_hat$gamma)
if(dast_model) {
if(include_mda_effect & is.null(mda_grid)) {
stop("The MDA coverage must be specified for each point on the grid through the argument 'mda_grid'")
}
if(is.null(time_pred)) {
stop("For a DAST model, the time of prediction must be specified through the argument 'time_pred'")
}
}
if(is.null(object$par_hat$tau2) &
include_nugget) {
stop("The nugget cannot be included in the predictive target
because it was not included when fitting the model")
}
if(is.null(f_target)) {
f_target <- list(linear_target = function(x) x)
}
if(is.null(pd_summary)) {
pd_summary <- list(mean = mean, sd = sd)
}
n_summaries <- length(pd_summary)
n_f <- length(f_target)
n_samples <- ncol(object$S_samples)
n_pred <- nrow(object$S_samples)
n_re <- length(object$re$samples)
re_names <- names(object$re$samples)
out <- list()
if(length(object$mu_pred)==1 && object$mu_pred==0 &&
include_covariates) {
stop("Covariates have not been provided; re-run pred_over_grid
and provide the covariates through the argument 'predictors'")
}
if(n_re==0 &&
include_re) {
stop("The categories of the randome effects variables have not been provided;
re-run pred_over_grid and provide the covariates through the argument 're_predictors'")
}
if(!include_covariates) {
mu_target <- 0
} else {
if(is.null(object$mu_pred)) stop("the output obtained from 'pred_S' does not
contain any covariates; if including covariates
in the predictive target these shuold be included
when running 'pred_S'")
mu_target <- object$mu_pred
}
if(!include_cov_offset) {
cov_offset <- 0
} else {
if(length(object$cov_offset)==1) {
stop("No covariate offset was included in the model;
set include_cov_offset = FALSE, or refit the model and include
the covariate offset")
}
cov_offset <- object$cov_offset
}
if(include_nugget) {
Z_sim <- matrix(rnorm(n_samples*n_pred,
sd = sqrt(object$par_hat$tau2)),
ncol = n_samples)
object$S_samples <- object$S_samples+Z_sim
}
if(is.matrix(mu_target)) {
out$lp_samples <- sapply(1:n_samples,
function(i)
mu_target[,i] + cov_offset +
object$S_samples[,i])
} else {
out$lp_samples <- sapply(1:n_samples,
function(i)
mu_target + cov_offset +
object$S_samples[,i])
}
if(include_re) {
n_dim_re <- sapply(1:n_re, function(i) length(object$re$samples[[i]]))
for(i in 1:n_re) {
for(j in 1:n_dim_re[i]) {
for(h in 1:n_samples) {
out$lp_samples[,h] <- out$lp_samples[,h] +
object$re$D_pred[[i]][,j]*object$re$samples[[i]][[j]][h]
}
}
}
}
names_f <- names(f_target)
if(is.null(names_f)) names_f <- paste("f_target_",1:length(f_target), sep = "")
names_s <- names(pd_summary)
if(is.null(pd_summary)) names_s <- paste("pd_summary_",1:length(f_target), sep = "")
out$target <- list()
for(i in 1:n_f) {
target_samples_i <-
f_target[[i]](out$lp_samples)
if(dast_model && include_mda_effect) {
alpha <- object$par_hat$alpha
if(is.null(alpha)) alpha <- object$fix_alpha
gamma <- object$par_hat$gamma
mda_effect_time_pred <- compute_mda_effect(rep(time_pred, n_pred),
mda_times = object$mda_times,
mda_grid, alpha = alpha,
gamma = gamma, kappa = object$power_val)
target_samples_i <- target_samples_i*mda_effect_time_pred
}
out$target[[paste(names_f[i])]] <- list()
for(j in 1:n_summaries) {
out$target[[paste(names_f[i])]][[paste(names_s[j])]] <-
apply(target_samples_i, 1, pd_summary[[j]])
}
}
out$grid_pred <- object$grid_pred
out$f_target <- names(f_target)
out$pd_summary <- names(pd_summary)
class(out) <- "RiskMap_pred_target_grid"
return(out)
}
pred_T_lb <-
pred_target_grid(pred_S_lb,
f_target = list(prev = function(x) exp(x)/(1+exp(x))),
pd_summary = list(mean = mean,
lower_lim = function(x) quantile(x, 0.025),
upper_lim = function(x) quantile(x, 0.975),
exceed20 = function(x) mean(x > 0.2),
exceed30 = function(x) mean(x > 0.3)))
plot(pred_T_lb, which_target = "prev", which_summary = "mean",
main = "Predictive mean")
plot(pred_T_lb, which_target = "prev", which_summary = "lower_lim",
main = "Quantile 0.025")
pred_T_lb <-
pred_target_grid(pred_S_lb,
f_target = list(prev = function(x) exp(x)/(1+exp(x))),
pd_summary = list(mean = mean,
lower_lim = function(x) quantile(x, 0.025),
upper_lim = function(x) quantile(x, 0.975),
exceed20 = function(x) mean(x > 0.2),
exceed30 = function(x) mean(x > 0.3)))
plot(pred_T_lb, which_target = "prev", which_summary = "mean",
main = "Predictive mean")
plot(pred_T_lb, which_target = "prev", which_summary = "lower_lim",
main = "Quantile 0.025")
plot(pred_T_lb, which_target = "prev", which_summary = "upper_lim",
main = "Quantile 0.975")
plot(pred_T_lb, which_target = "prev", which_summary = "exceed20",
main = "Exceedance probability (L = 0.2)")
plot(pred_T_lb, which_target = "prev", which_summary = "exceed30",
main = "Exceedance probability (L = 0.3)")
rm(list = ls())
library(RiskMap)
library(sf)
library(ggplot2)
data("liberia")
# Convert to an sf object
liberia_sf <- st_as_sf(liberia, coords = c("long", "lat"), crs = 4326)
crs_lb <- propose_utm(liberia_sf)
liberia_sf <- st_transform(liberia_sf, crs = crs_lb)
lb_fit <- glgpm(npos ~ log(elevation) + gp(),
den = ntest,
family = "binomial",
data = liberia_sf)
library(rgeoboundaries)
shp_lb_0 <- geoboundaries(country = "liberia", adm_lvl = "adm0")
shp_lb_0 <- st_transform(shp_lb_0, crs=crs_lb)
shp_lb_1 <- geoboundaries(country = "liberia", adm_lvl = "adm1")
shp_lb_1 <- st_transform(shp_lb_1, crs=crs_lb)
grid_lb <- create_grid(shp_lb_0, spat_res = 5)
library(elevatr)
elevation <- get_elev_point(st_as_sf(grid_lb), prj = crs_lb, src = "aws")$elevation
pred_lb <- data.frame(elvation=elevation)
pred_S_lb <-
pred_over_grid(lb_fit, grid_pred = grid_lb,
predictors = pred_lb, type="joint")
pred_area <- pred_target_shp(pred_S_lb, shp = shp_lb_1,
shp_target = function(Tx) mean(Tx),
f_target = list(prev =
function(lp) exp(lp)/(1+exp(lp))),
pd_summary = list(mean = mean,
exceed20 = function(x) mean(x > 0.2)),
col_names = "shapeName")
# Plot point predictions of average prevalence
plot(pred_area, which_target = "prev", which_summary = "mean",
palette = "RdYlGn",
limits = c(0.1, 0.30),
breaks =  seq(0.1, 0.30, by = 0.05)) +
guides(fill=guide_legend(title="Prevalence")) +
ggtitle("Average prevalence \n (no weights)") +
theme(plot.title = element_text(size = 15))
# Plot of the exceedance probabilities
plot(pred_area, which_target = "prev", which_summary = "exceed20",
palette = "RdYlGn",
limits = c(0, 1),
breaks = seq(0,1, by = 0.1)) +
guides(fill=guide_legend(title="Probability")) +
ggtitle("Exceedance probability (L = 0.2) \n (no weights)") +
theme(plot.title = element_text(size = 15))
# Obtaining population density
library(wpgpDownloadR)
lbr_url <- wpgpGetCountryDataset(ISO3 = "LBR", covariate = "ppp_2014")
library(terra)
lbr_pop <- rast(lbr_url)
lbr_pop <- project(lbr_pop, "EPSG:32629")
# Extra pop density weights at the prediction grid
weights_pred <- extract(lbr_pop, st_as_sf(grid_lb))$lbr_ppp_2014
pred_area_w <- pred_target_shp(pred_S_lb, shp = shp_lb_1,
shp_target = function(Tx) sum(Tx),
f_target = list(prev =
function(lp) exp(lp)/(1+exp(lp))),
pd_summary = list(mean = mean,
exceed20 = function(x) mean(x > 0.2)),
weights = weights_pred,
standardize_weights = TRUE,
col_names = "shapeName")
# Plot point predictions of average prevalence (weighted)
plot(pred_area_w, which_target = "prev", which_summary = "mean",
palette = "RdYlGn",
limits = c(0.1, 0.30),
breaks =  seq(0.1, 0.30, by = 0.05)) +
guides(fill=guide_legend(title="Prevalence")) +
ggtitle("Average prevalence \n (population weighted)") +
theme(plot.title = element_text(size = 15))
pred_area <- pred_target_shp(pred_S_lb, shp = shp_lb_1,
shp_target = function(Tx) mean(Tx),
f_target = list(prev =
function(lp) exp(lp)/(1+exp(lp))),
pd_summary = list(mean = mean,
exceed20 = function(x) mean(x > 0.2)),
col_names = "shapeName")
# Plot point predictions of average prevalence
plot(pred_area, which_target = "prev", which_summary = "mean",
palette = "RdYlGn",
limits = c(0.1, 0.30),
breaks =  seq(0.1, 0.30, by = 0.05)) +
guides(fill=guide_legend(title="Prevalence")) +
ggtitle("Average prevalence \n (no weights)") +
theme(plot.title = element_text(size = 15))
# Plot of the exceedance probabilities (weighted)
plot(pred_area_w, which_target = "prev", which_summary = "exceed20",
palette = "RdYlGn",
limits = c(0, 1),
breaks = seq(0,1, by = 0.1)) +
guides(fill=guide_legend(title="Probability")) +
ggtitle("Exceedance probability (L = 0.2) \n (population weighted)") +
theme(plot.title = element_text(size = 15))
